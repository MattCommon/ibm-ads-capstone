{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.image as img\n",
    "from PIL import Image\n",
    "import collections\n",
    "from keras.utils import to_categorical\n",
    "from random import randint\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths for training and test data\n",
    "trainPath = \"input/seg_train/\"\n",
    "testPath = \"input/seg_test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to load images\n",
    "def load_image(infilename):\n",
    "    image = Image.open(infilename)\n",
    "    image.load()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to read in images and labels\n",
    "def read_images(folder):\n",
    "    \n",
    "    subFolders = os.listdir(folder)\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # read in images, convert to arrays, resize if necessary and append labels\n",
    "    for subFolder in subFolders:\n",
    "        \n",
    "        subFolderPath = folder + subFolder + \"/\"\n",
    "        print(\"Reading in images from \" + subFolderPath)\n",
    "        \n",
    "        for file in os.listdir(subFolderPath):\n",
    "            if file.endswith(\"jpg\"):\n",
    "                # read in image\n",
    "                image = load_image(subFolderPath + file)\n",
    "\n",
    "                # append image\n",
    "                images.append(image)\n",
    "\n",
    "                # append labels\n",
    "                labels.append(subFolder)\n",
    "    \n",
    "    # Checks\n",
    "    print(\"Number of images = \" + str(len(images)))\n",
    "    print(\"Number of labels = \" + str(len(labels)))\n",
    "    print(\"Label frequencies: \" + str(collections.Counter(labels)))\n",
    "    \n",
    "    # return as arrays\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in images from input/seg_train/buildings/\n",
      "Reading in images from input/seg_train/forest/\n",
      "Reading in images from input/seg_train/glacier/\n",
      "Reading in images from input/seg_train/mountain/\n",
      "Reading in images from input/seg_train/sea/\n",
      "Reading in images from input/seg_train/street/\n",
      "Number of images = 14034\n",
      "Number of labels = 14034\n",
      "Label frequencies: Counter({'mountain': 2512, 'glacier': 2404, 'street': 2382, 'sea': 2274, 'forest': 2271, 'buildings': 2191})\n"
     ]
    }
   ],
   "source": [
    "# Read in training data\n",
    "images_train, labels_train = read_images(trainPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in images from input/seg_test/buildings/\n",
      "Reading in images from input/seg_test/forest/\n",
      "Reading in images from input/seg_test/glacier/\n",
      "Reading in images from input/seg_test/mountain/\n",
      "Reading in images from input/seg_test/sea/\n",
      "Reading in images from input/seg_test/street/\n",
      "Number of images = 3000\n",
      "Number of labels = 3000\n",
      "Label frequencies: Counter({'glacier': 553, 'mountain': 525, 'sea': 510, 'street': 501, 'forest': 474, 'buildings': 437})\n"
     ]
    }
   ],
   "source": [
    "# Read in test data\n",
    "images_test, labels_test = read_images(testPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle training datasets\n",
    "images_train, labels_train = shuffle(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images = 3000\n",
      "Number of labels = 3000\n",
      "Label frequencies: Counter({'mountain': 538, 'glacier': 537, 'sea': 498, 'forest': 478, 'street': 475, 'buildings': 474})\n"
     ]
    }
   ],
   "source": [
    "# Take 3000 images from training for validation\n",
    "images_valid = images_train[-3000:]\n",
    "labels_valid = labels_train[-3000:]\n",
    "print(\"Number of images = \" + str(len(images_valid)))\n",
    "print(\"Number of labels = \" + str(len(labels_valid)))\n",
    "print(\"Label frequencies: \" + str(collections.Counter(labels_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images = 11034\n",
      "Number of labels = 11034\n",
      "Label frequencies: Counter({'mountain': 1974, 'street': 1907, 'glacier': 1867, 'forest': 1793, 'sea': 1776, 'buildings': 1717})\n"
     ]
    }
   ],
   "source": [
    "# Remove validation images from training dataset\n",
    "images_train = images_train[:-3000]\n",
    "labels_train = labels_train[:-3000]\n",
    "print(\"Number of images = \" + str(len(images_train)))\n",
    "print(\"Number of labels = \" + str(len(labels_train)))\n",
    "print(\"Label frequencies: \" + str(collections.Counter(labels_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to convert images to arrays, resizing if necessary\n",
    "def convertImages(images):\n",
    "    \n",
    "    X_data = []\n",
    "    \n",
    "    for image in images:\n",
    "        \n",
    "        # convert to array\n",
    "        x = np.asarray(image, dtype=\"int32\")\n",
    "            \n",
    "        # resize if necessary\n",
    "        if x.shape != (150, 150, 3):\n",
    "            resized = image.resize((150, 150), Image.LANCZOS)\n",
    "            x = np.asarray(resized, dtype=\"int32\")\n",
    "            \n",
    "        # append data\n",
    "        X_data.append(x)\n",
    "    \n",
    "    return np.array(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = convertImages(images_train)\n",
    "X_test = convertImages(images_test)\n",
    "X_valid = convertImages(images_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'glacier': 0, 'mountain': 1, 'sea': 2, 'forest': 3, 'street': 4, 'buildings': 5}\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary which maps class to an integer label\n",
    "classDict = dict((label, counter) for counter, label in enumerate(list(set(labels_train))))\n",
    "print(classDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of classes\n",
    "classes = len(classDict)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to one-hot encode labels\n",
    "def oneHot(labels, classDict, classes):\n",
    "    \n",
    "    # convert labels to integer values\n",
    "    values = []\n",
    "    for label in labels:\n",
    "        values.append(classDict[label])\n",
    "    \n",
    "    # one-hot encode label values    \n",
    "    onehot = to_categorical(values, classes)\n",
    "    \n",
    "    return np.array(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = oneHot(labels_train, classDict, classes)\n",
    "y_test = oneHot(labels_test, classDict, classes)\n",
    "y_valid = oneHot(labels_valid, classDict, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pickle function so that data can be saved and imported into next stage\n",
    "def saveData(data, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saveData\n",
    "saveData(X_train[:5000], 'X_train1.pickle')\n",
    "saveData(X_train[5000:], 'X_train2.pickle')\n",
    "saveData(y_train, 'y_train.pickle')\n",
    "saveData(images_train, 'images_train.pickle')\n",
    "saveData(labels_train, 'labels_train.pickle')\n",
    "saveData(X_test, 'X_test.pickle')\n",
    "saveData(y_test, 'y_test.pickle')\n",
    "saveData(images_test, 'images_test.pickle')\n",
    "saveData(labels_test, 'labels_test.pickle')\n",
    "saveData(X_valid, 'X_valid.pickle')\n",
    "saveData(y_valid, 'y_valid.pickle')\n",
    "saveData(images_valid, 'images_valid.pickle')\n",
    "saveData(labels_valid, 'labels_valid.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Local Disk\n",
      " Volume Serial Number is 0671-FAEA\n",
      "\n",
      " Directory of C:\\Users\\mattc\\Coursera\\ibm-ads-capstone\n",
      "\n",
      "17/03/2019  20:07       202,558,540 images_test.pickle\n",
      "17/03/2019  20:06       744,997,171 images_train.pickle\n",
      "17/03/2019  20:07       202,605,340 images_valid.pickle\n",
      "17/03/2019  20:07             6,065 labels_test.pickle\n",
      "17/03/2019  20:06            22,151 labels_train.pickle\n",
      "17/03/2019  20:07             6,065 labels_valid.pickle\n",
      "17/03/2019  20:06       810,000,160 X_test.pickle\n",
      "17/03/2019  20:06     1,350,000,160 X_train1.pickle\n",
      "17/03/2019  20:06     1,629,180,160 X_train2.pickle\n",
      "17/03/2019  20:07       810,000,160 X_valid.pickle\n",
      "17/03/2019  20:06            72,155 y_test.pickle\n",
      "17/03/2019  20:06           264,971 y_train.pickle\n",
      "17/03/2019  20:07            72,155 y_valid.pickle\n",
      "              13 File(s)  5,749,785,253 bytes\n",
      "               0 Dir(s)  21,017,133,056 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir *.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
